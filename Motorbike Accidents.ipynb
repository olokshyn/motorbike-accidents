{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from fbprophet import Prophet\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'datasets/motorbike_ambulance_calls.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motorbike_data = (\n",
    "    pd.read_csv(\n",
    "        DATASET_PATH,\n",
    "        parse_dates=['date'],\n",
    "        dayfirst=False,\n",
    "    )\n",
    "    .set_index('index')\n",
    ")\n",
    "motorbike_data.info()\n",
    "motorbike_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datetime_feature(data):\n",
    "    return (\n",
    "        data\n",
    "        .assign(datetime=lambda x: (\n",
    "            x.apply(\n",
    "                lambda y: (\n",
    "                    y['date'].replace(hour=y['hr'])\n",
    "                ), \n",
    "                axis='columns'\n",
    "            )\n",
    "        ))\n",
    "    )\n",
    "\n",
    "def convert_datetime_to_unix_timestamp(data):\n",
    "    return (\n",
    "        data\n",
    "        .assign(datetime=lambda x: x['datetime'].astype(np.int64) // 10**9)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data = (\n",
    "    motorbike_data\n",
    "    .pipe(add_datetime_feature)\n",
    "    .pipe(convert_datetime_to_unix_timestamp)\n",
    ")\n",
    "\n",
    "analysis_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'cnt'\n",
    "numerical_features = {\n",
    "    'temp', 'atemp', 'hum', 'windspeed',\n",
    "    'yr', 'mnth', 'hr', 'datetime'\n",
    "}\n",
    "numerical_and_target_features = numerical_features | set([target_feature])\n",
    "categorical_features = {\n",
    "    'season', 'holiday', 'weekday', 'weathersit', 'workingday'\n",
    "}\n",
    "leftout_features = (\n",
    "    set(motorbike_data.columns) \n",
    "    - set([target_feature])\n",
    "    - numerical_features\n",
    "    - categorical_features\n",
    ")\n",
    "leftout_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    analysis_data\n",
    "    .reindex(columns=numerical_and_target_features)\n",
    "    .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features are already within domains.\n",
    "`windspeed` has to be scaled to [0, 1] interval, ordinal and categorical features have to be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    analysis_data\n",
    "    .isnull()\n",
    "    .any()\n",
    "    .any()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Pearson correlation coefficient pairwise to see if there is a linear dependency between features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    analysis_data\n",
    "    .reindex(columns=numerical_and_target_features)\n",
    "    .corr()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max correlation for each feature:')\n",
    "(\n",
    "    analysis_data\n",
    "    .reindex(columns=numerical_and_target_features)\n",
    "    .corr()\n",
    "    .pipe(lambda x: x.subtract(np.diag([1.0] * len(x.columns))))\n",
    "    .apply(\n",
    "        lambda x: pd.Series({\n",
    "            'feature': x.abs().idxmax(), \n",
    "            'corr': x[x.abs().idxmax()]\n",
    "        }), \n",
    "        axis='columns'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strong linear dependencies are not observed between the target variable and the numerical features. The target variable `cnt` is correlated most with `temp` feature. At the same time, features `temp` and `atemp` are strongly correlated, so the model should not use both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    (\n",
    "        analysis_data\n",
    "        .reindex(columns=numerical_and_target_features)\n",
    "        .drop(columns='temp')\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features: workingday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    x='hr',\n",
    "    y='cnt',\n",
    "    kind='box',\n",
    "    hue='workingday',\n",
    "    data=analysis_data,\n",
    "    aspect=2\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, on working days more accidents happen in the rush hours - 7.00 - 8.00 and 16.00 - 20.00. On non-working days, the accidents are distributed closer to the middle of the day.\n",
    "\n",
    "For both working and non-working days, the dependency between `hr` and `cnt` doesn't seem to be linear.\n",
    "\n",
    "**Observation 1: motorbike accidents are distributed differently over time depending on workingday**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features: season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    x='hr',\n",
    "    y='cnt',\n",
    "    kind='box',\n",
    "    hue='workingday',\n",
    "    row='season',\n",
    "    data=analysis_data,\n",
    "    aspect=2\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features: weathersit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    x='hr',\n",
    "    y='cnt',\n",
    "    kind='box',\n",
    "    hue='workingday',\n",
    "    row='weathersit',\n",
    "    data=analysis_data,\n",
    "    aspect=2\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    x='weathersit',\n",
    "    y='cnt',\n",
    "    data=analysis_data,\n",
    "    aspect=2\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    analysis_data\n",
    "    .groupby('weathersit')\n",
    "    ['cnt']\n",
    "    .sum()\n",
    "    .plot(kind='bar', title='Number of accidents by weathersit')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical feature: weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    x='weekday',\n",
    "    y='cnt',\n",
    "    kind='box',\n",
    "    hue='workingday',\n",
    "    data=analysis_data,\n",
    "    aspect=2\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = motorbike_data.drop(columns=target_feature), motorbike_data[target_feature]\n",
    "\n",
    "# No time machine: use 'past' data for training, use 'future' data for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, shuffle=False\n",
    ")\n",
    "\n",
    "assert X_train.index.max() < X_test.index.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_numerical_features = list(numerical_features - {'temp', 'datetime'})\n",
    "print('Numerical features:', model_numerical_features)\n",
    "model_categorical_features = list(categorical_features)\n",
    "print('Categorical features:', model_categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        # In case serving data has missing values\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        # Need to scale windspeed\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        # In case serving data has missing values\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(categories='auto', \n",
    "                                 sparse=False, \n",
    "                                 handle_unknown='ignore'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pipeline = Pipeline(steps=[\n",
    "    (\n",
    "        'features',\n",
    "        ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\n",
    "                    'numerical',\n",
    "                    numerical_transformer, \n",
    "                    model_numerical_features\n",
    "                ),\n",
    "                (\n",
    "                    'categorical', \n",
    "                    categorical_transformer, \n",
    "                    model_categorical_features\n",
    "                )\n",
    "            ],\n",
    "            remainder='drop'\n",
    "        )\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(model, use_grid_search=True, **grid_search_params):\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('features', features_pipeline),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    if use_grid_search:\n",
    "        grid_search_params = {\n",
    "            'cv': TimeSeriesSplit(n_splits=5),\n",
    "\n",
    "            **grid_search_params\n",
    "        }\n",
    "        return GridSearchCV(pipeline, **grid_search_params)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction(model_name, prediction):\n",
    "    rmse = math.sqrt(\n",
    "        mean_squared_error(y_test, prediction)\n",
    "    )\n",
    "    print(f'{model_name} RMSE: ', rmse)\n",
    "    sns.relplot(\n",
    "        x=model_name,\n",
    "        y='y_test',\n",
    "        data=pd.DataFrame({\n",
    "            model_name: prediction,\n",
    "            'y_test': y_test\n",
    "        })\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, model, **grid_search_params):\n",
    "    pipeline = build_pipeline(\n",
    "        model,\n",
    "        use_grid_search='param_grid' in grid_search_params,\n",
    "        **grid_search_params\n",
    "    )\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    evaluate_prediction(model_name, pipeline.predict(X_test))\n",
    "    if hasattr(pipeline, 'best_params_'):\n",
    "        print('Best params: ', pipeline.best_params_)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted before, there are no strong linear relationships in the data, so linear regression won't work well here. Anyway let's fit it just to have a baseline and see if the pipeline works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression = evaluate_model('linear regression', LinearRegression())\n",
    "print('R2 score: ', linear_regression.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple non-linear relations like working/non-working day and rush hours should be well-captured by a decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "decision_tree = evaluate_model(\n",
    "    'decision tree', \n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    param_grid={\n",
    "        # Already found the best params\n",
    "        'model__max_depth': [20]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree has a drawback: it easily overfits, especially on small datasets like the one we have here. To reduce overfitting we can use random forest and limit max_depth more aggresively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_forest = evaluate_model(\n",
    "    'random forest',\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid={\n",
    "        # Already found the best params\n",
    "        'model__n_estimators': [40],\n",
    "        'model__max_depth': [20]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transform_data_for_prophet(X, y):\n",
    "    df = (\n",
    "        pd.concat(\n",
    "            [\n",
    "                (\n",
    "                    X\n",
    "                    .pipe(add_datetime_feature)\n",
    "                    ['datetime']\n",
    "                    .rename('ds')\n",
    "                ),\n",
    "                y.rename('y')\n",
    "            ],\n",
    "            axis='columns',\n",
    "            sort=False\n",
    "        )\n",
    "    )\n",
    "    holidays = (\n",
    "        X\n",
    "        .groupby('date', as_index=False)\n",
    "        .first()\n",
    "        .assign(holiday=lambda x: np.where(\n",
    "            x['holiday'] == 1,\n",
    "            'holiday',\n",
    "            np.where(\n",
    "                x['workingday'] == 0,\n",
    "                'weekend',\n",
    "                None\n",
    "            )\n",
    "        ))\n",
    "        [lambda x: x['workingday'] == 0]\n",
    "        [['date', 'holiday']]\n",
    "        .rename(columns={\n",
    "            'date': 'ds'\n",
    "        })\n",
    "    )\n",
    "    return df, holidays\n",
    "\n",
    "(\n",
    "    X_train\n",
    "    .pipe(_transform_data_for_prophet, y=y_train)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProphetEstimator(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self, **prophet_args):\n",
    "        self.prophet_args = prophet_args\n",
    "        self.model = None\n",
    "        self.last_prediction = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        df, holidays = _transform_data_for_prophet(X, y)\n",
    "        \n",
    "        prophet_args = self.prophet_args.copy()\n",
    "        if prophet_args.pop('use_holidays', None):\n",
    "            prophet_args['holidays'] = holidays\n",
    "            \n",
    "        quarterly_seasonality = prophet_args.pop('quarterly_seasonality', None)\n",
    "        montly_seasonality = prophet_args.pop('montly_seasonality', None)\n",
    "        hourly_seasonality = prophet_args.pop('hourly_seasonality', None)\n",
    "        \n",
    "        self.model = Prophet(**prophet_args)\n",
    "        \n",
    "        if quarterly_seasonality:\n",
    "            self.model.add_seasonality(\n",
    "                name='quarterly',\n",
    "                period=365.25 / 4,\n",
    "                fourier_order=5\n",
    "            )\n",
    "        if montly_seasonality:\n",
    "            self.model.add_seasonality(\n",
    "                name='montly',\n",
    "                period=30.5,\n",
    "                fourier_order=5\n",
    "            )\n",
    "        if hourly_seasonality:\n",
    "            self.model.add_seasonality(\n",
    "                name='hourly',\n",
    "                period=24,\n",
    "                fourier_order=5\n",
    "            )\n",
    "            \n",
    "        self.model.fit(df)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self.model:\n",
    "            raise RuntimeError('Neet to train first')\n",
    "        future = (\n",
    "            X\n",
    "            .pipe(add_datetime_feature)\n",
    "            [['datetime']]\n",
    "            .rename(columns={\n",
    "                'datetime': 'ds'\n",
    "            })\n",
    "        )\n",
    "        self.last_prediction = self.model.predict(future)\n",
    "        yhat = self.last_prediction['yhat'].copy()\n",
    "        yhat.index = X.index\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet1 = ProphetEstimator(\n",
    "    yearly_seasonality=True,\n",
    "    quarterly_seasonality=True,\n",
    "    # Montly seasonality actually makes it worse.\n",
    "#     montly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=True,\n",
    "    hourly_seasonality=True,\n",
    "    use_holidays=True\n",
    ")\n",
    "\n",
    "prophet1.fit(X_train, y_train)\n",
    "evaluate_prediction('prophet 1', prophet1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet1.model.plot(prophet.last_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet1.model.plot_components(prophet.last_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
