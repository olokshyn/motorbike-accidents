{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
    ")\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'datasets'\n",
    "FIGURES_PATH = 'figures'\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('muted')\n",
    "sns.palplot(sns.color_palette())\n",
    "\n",
    "season_order = ['winter', 'spring', 'summer', 'autumn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motorbike_data = (\n",
    "    pd.read_csv(\n",
    "        os.path.join(DATASET_PATH, 'cleanted_motorbike_ambulance_calls.csv'),\n",
    "        parse_dates=['date'],\n",
    "        dayfirst=False,\n",
    "    )\n",
    "    .assign(\n",
    "        yr=lambda x: np.where(\n",
    "            x['yr'] == 2011,\n",
    "            0,\n",
    "            1\n",
    "        )\n",
    "    )\n",
    "    .assign(\n",
    "        season=lambda x: (\n",
    "            pd.Categorical(\n",
    "                x['season'], \n",
    "                categories=season_order, \n",
    "                ordered=True\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    .drop(columns='was_missing')\n",
    ")\n",
    "motorbike_data.info()\n",
    "motorbike_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = motorbike_data.drop(columns='cnt'), motorbike_data['cnt']\n",
    "\n",
    "# No time machine: use 'past' data for training, use 'future' data for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, shuffle=False\n",
    ")\n",
    "\n",
    "assert X_train.index.max() < X_test.index.min()\n",
    "\n",
    "print('Train: ', X_train[['date', 'hr']].nlargest(1, columns=['date', 'hr']))\n",
    "print('Test: ', X_test[['date', 'hr']].nsmallest(1, columns=['date', 'hr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMeanStdTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, feature, lags=None):\n",
    "        self.feature = feature\n",
    "        self.feature_mean_and_std = None\n",
    "        self.lags = lags\n",
    "        \n",
    "    def _get_lags(self):\n",
    "        return sorted(self.lags) if self.lags else [0]\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_mean_and_std = (\n",
    "            X[['hr', self.feature]]\n",
    "            .groupby('hr')\n",
    "            [self.feature]\n",
    "            .agg(['mean', 'std'])\n",
    "            .rename(columns={\n",
    "                'mean': f'{self.feature}_mean', \n",
    "                'std': f'{self.feature}_std'\n",
    "            })\n",
    "        )    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.feature_mean_and_std is None:\n",
    "            raise RuntimeError('Need to fit() first!')\n",
    "        \n",
    "        data_with_feature = (\n",
    "            X\n",
    "            [['date', 'hr']]\n",
    "            .merge(\n",
    "                self.feature_mean_and_std,\n",
    "                how='left',\n",
    "                left_on='hr',\n",
    "                right_index=True\n",
    "            )\n",
    "            .sort_values(['date', 'hr'])\n",
    "        )\n",
    "        \n",
    "        for lag in self._get_lags():\n",
    "            if lag == 0:\n",
    "                continue\n",
    "            data_with_feature = (\n",
    "                data_with_feature\n",
    "                .assign(**{\n",
    "                    f'{self.feature}_mean_{lag}h_lag': lambda x: (\n",
    "                        x[f'{self.feature}_mean']\n",
    "                        .shift(\n",
    "                            lag, \n",
    "                            fill_value=x.iloc[:lag][f'{self.feature}_mean'].mean()\n",
    "                        )\n",
    "                    ),\n",
    "                    f'{self.feature}_std_{lag}h_lag': lambda x: (\n",
    "                        x[f'{self.feature}_std']\n",
    "                        .shift(\n",
    "                            lag, \n",
    "                            fill_value=x.iloc[:lag][f'{self.feature}_std'].mean()\n",
    "                        )\n",
    "                    )\n",
    "                })\n",
    "            )\n",
    "            \n",
    "        if 0 not in self._get_lags():\n",
    "            data_with_feature = (\n",
    "                data_with_feature\n",
    "                .drop(columns=[f'{self.feature}_mean', f'{self.feature}_std'])\n",
    "            )\n",
    "        \n",
    "        return (\n",
    "            # We sorted, so we have to restore the original ordering\n",
    "            X\n",
    "            [['date', 'hr']]\n",
    "            .merge(\n",
    "                data_with_feature,\n",
    "                how='left',\n",
    "                on=['date', 'hr']\n",
    "            )\n",
    "            .drop(columns=['date', 'hr'])\n",
    "        )\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        feature_names = []\n",
    "        for lag in self._get_lags():\n",
    "            if lag == 0:\n",
    "                feature_names.extend([\n",
    "                    f'{self.feature}_mean', \n",
    "                    f'{self.feature}_std'\n",
    "                ])\n",
    "            else:\n",
    "                feature_names.extend([\n",
    "                    f'{self.feature}_mean_{lag}h_lag', \n",
    "                    f'{self.feature}_std_{lag}h_lag'\n",
    "                ])\n",
    "        return feature_names\n",
    "    \n",
    "(\n",
    "    FeatureMeanStdTransformer('hum', lags=[1, 2, 3, 0])\n",
    "    .fit_transform(X_train, y_train)\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CntMeanStdTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, lags=None):\n",
    "        self.feature_transformer = FeatureMeanStdTransformer('cnt', lags)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if y is None:\n",
    "            raise RuntimeError('Target variable is required for fitting!')\n",
    "        data = (\n",
    "            pd.concat(\n",
    "                [X['hr'], y],\n",
    "                axis='columns',\n",
    "                sort=False\n",
    "            )\n",
    "        )\n",
    "        self.feature_transformer.fit(data)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.feature_transformer.transform(X)\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        return self.feature_transformer.get_feature_names(in_names)\n",
    "    \n",
    "(\n",
    "    CntMeanStdTransformer(lags=[1, 2, 3, 0])\n",
    "    .fit_transform(X_train, y_train)\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLagTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, feature, lags):\n",
    "        self.feature = feature\n",
    "        self.lags = lags\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        sorted_data = (\n",
    "            X\n",
    "            [['date', 'hr', self.feature]]\n",
    "            .sort_values(['date', 'hr'])\n",
    "        )\n",
    "        \n",
    "        for lag in self.lags:\n",
    "            sorted_data = (\n",
    "                sorted_data\n",
    "                .assign(**{\n",
    "                    f'{self.feature}_{lag}h_lag': lambda x: (\n",
    "                        x[f'{self.feature}']\n",
    "                        .shift(lag)\n",
    "                    )\n",
    "                })\n",
    "            )\n",
    "            \n",
    "        return (\n",
    "            # We sorted, so we have to restore the original ordering\n",
    "            X\n",
    "            [['date', 'hr']]\n",
    "            .merge(\n",
    "                sorted_data,\n",
    "                how='left',\n",
    "                on=['date', 'hr']\n",
    "            )\n",
    "            .drop(columns=['date', 'hr', self.feature])\n",
    "        )\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        feature_names = []\n",
    "        for lag in self.lags:\n",
    "            feature_names.append(f'{self.feature}_{lag}h_lag')\n",
    "        return feature_names\n",
    "\n",
    "(\n",
    "    FeatureLagTransformer('hum', lags=[1, 2, 3])\n",
    "    .fit_transform(X_train, y_train)\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsRushHourTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return (\n",
    "            X\n",
    "            [['hr', 'workingday']]\n",
    "            .assign(\n",
    "                is_rush_hour=lambda x: (\n",
    "                    (\n",
    "                        (x['workingday'] == 1)\n",
    "                        &\n",
    "                        (\n",
    "                            ((x['hr'] >= 7) & (x['hr'] <= 9))\n",
    "                            |\n",
    "                            ((x['hr'] >= 16) & (x['hr'] <= 19))\n",
    "                        )\n",
    "                    )\n",
    "                    |\n",
    "                    (\n",
    "                        (x['workingday'] == 0)\n",
    "                        &\n",
    "                        (x['hr'] >= 11) & (x['hr'] <= 17)\n",
    "                    )\n",
    "                ).astype('int64')\n",
    "            )\n",
    "            .drop(columns=['hr', 'workingday'])\n",
    "        )\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        return ['is_rush_hour']\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(\n",
    "        X_train\n",
    "        .set_index(['date', 'hr'], drop=False)\n",
    "        .groupby('workingday', as_index=False)\n",
    "        .head(24)\n",
    "        .pipe(IsRushHourTransformer().transform)\n",
    "        .transpose()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamedFeaturesPipeline(Pipeline):\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        feature_names = in_names\n",
    "        for step_name, step in self.steps:\n",
    "            try:\n",
    "                feature_names = step.get_feature_names(feature_names)\n",
    "            except AttributeError as exc:\n",
    "                print(f'Beware: {step_name} does not have get_feature_names(): {exc}')\n",
    "        return feature_names\n",
    "    \n",
    "class NamedFeaturesFeatureUnion(FeatureUnion):\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        feature_names = []\n",
    "        for step_name, step in self.transformer_list:\n",
    "            feature_names.extend(step.get_feature_names(in_names))\n",
    "        return feature_names\n",
    "\n",
    "class NamedFeaturesColumnTransformer(ColumnTransformer):\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        passthrough_features = []\n",
    "        if in_names is not None:\n",
    "            passthrough_features = list(in_names)\n",
    "        else:\n",
    "            passthrough_features = []\n",
    "            \n",
    "        feature_names = []\n",
    "        for step_name, step, step_features in self.transformers_:\n",
    "            if step_name == 'remainder':\n",
    "                continue\n",
    "            passthrough_features = (\n",
    "                [x for x in passthrough_features if x not in step_features]\n",
    "            )\n",
    "            print(f'At {step_name} with features {step_features}')\n",
    "            feature_names.extend(step.get_feature_names(step_features))\n",
    "            \n",
    "        if self.remainder == 'passthrough':\n",
    "            feature_names.extend(passthrough_features)\n",
    "        return feature_names\n",
    "\n",
    "class NamedFeaturesNotChangedMixin:\n",
    "    \n",
    "    def get_feature_names(self, in_names=None):\n",
    "        return in_names\n",
    "    \n",
    "class NamedFeaturesSimpleImputer(NamedFeaturesNotChangedMixin, SimpleImputer):\n",
    "    pass\n",
    "\n",
    "class NamedFeaturesStandardScaler(NamedFeaturesNotChangedMixin, StandardScaler):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_features_pipeline = (\n",
    "    NamedFeaturesColumnTransformer(\n",
    "        [\n",
    "            (\n",
    "                'numerical_features',\n",
    "                NamedFeaturesPipeline([\n",
    "                    ('imputer', NamedFeaturesSimpleImputer(strategy='mean')),\n",
    "                    ('scaler', NamedFeaturesStandardScaler())\n",
    "                ]),\n",
    "                ['hr', 'temp', 'hum', 'windspeed']\n",
    "            ),\n",
    "            (\n",
    "                'categorical_features',\n",
    "                NamedFeaturesPipeline([\n",
    "                    ('imputer', NamedFeaturesSimpleImputer(strategy='most_frequent')),\n",
    "                    (\n",
    "                        'onehot', \n",
    "                        OneHotEncoder(\n",
    "                            categories='auto', \n",
    "                            sparse=False, \n",
    "                            handle_unknown='ignore'\n",
    "                        )\n",
    "                    )\n",
    "                ]),\n",
    "                ['mnth', 'season', 'weekday', 'weathersit']\n",
    "            ),\n",
    "            (\n",
    "                'unmodified_features',\n",
    "                NamedFeaturesSimpleImputer(strategy='most_frequent'),\n",
    "                ['yr', 'holiday', 'workingday']\n",
    "            )\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_numerical_features_pipeline = NamedFeaturesPipeline([\n",
    "    (\n",
    "        'custom_numerical_features',\n",
    "        NamedFeaturesFeatureUnion([\n",
    "            ('cnt_mean_std', CntMeanStdTransformer(lags=[0, 1, 2, 3, 6, 12])),\n",
    "            ('hum_mean_std', FeatureMeanStdTransformer('hum', lags=[0, 1, 2, 3, 6, 12])),\n",
    "            ('temp_mean_std', FeatureMeanStdTransformer('temp', lags=[0, 1, 2, 3, 6, 12])),\n",
    "            \n",
    "            ('hum_lag', FeatureLagTransformer('hum', lags=[1, 2, 3])),\n",
    "            ('temp_lag', FeatureLagTransformer('temp', lags=[1, 2, 3])),\n",
    "            ('windspeed_lag', FeatureLagTransformer('windspeed', lags=[1, 2, 3]))\n",
    "        ])\n",
    "    ),\n",
    "    ('imputer', NamedFeaturesSimpleImputer(strategy='mean')),\n",
    "    ('scaler', NamedFeaturesStandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_categorical_features_pipeline = NamedFeaturesPipeline([\n",
    "    (\n",
    "        'custom_categorical_features',\n",
    "        NamedFeaturesFeatureUnion([\n",
    "            ('weathersit_lag', FeatureLagTransformer('weathersit', lags=[1, 3, 24])),\n",
    "        ])\n",
    "    ),\n",
    "    ('imputer', NamedFeaturesSimpleImputer(strategy='most_frequent')),\n",
    "    (\n",
    "        'onehot', \n",
    "        OneHotEncoder(\n",
    "            categories='auto', \n",
    "            sparse=False, \n",
    "            handle_unknown='ignore'\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "custom_categorical_features_pipeline = NamedFeaturesFeatureUnion([\n",
    "    ('categorical_features', custom_categorical_features_pipeline),\n",
    "    ('is_rush_hour', IsRushHourTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_features_pipeline = NamedFeaturesFeatureUnion([\n",
    "    ('numerical_features', custom_numerical_features_pipeline),\n",
    "    ('categorical_features', custom_categorical_features_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pipeline = NamedFeaturesFeatureUnion([\n",
    "    (\n",
    "        'basic_features',\n",
    "        basic_features_pipeline\n",
    "    ),\n",
    "    (\n",
    "        'custom_features',\n",
    "        custom_features_pipeline\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = features_pipeline.fit(X_train, y_train)\n",
    "feature_names = p.get_feature_names(X_train.columns)\n",
    "assert p.transform(X_train).shape[1] == len(feature_names)\n",
    "t_X_train = pd.DataFrame(p.transform(X_train), columns=feature_names)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train[:24])\n",
    "display(X_train[48:72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(\n",
    "        t_X_train\n",
    "        [:24]\n",
    "    )\n",
    "    display(\n",
    "        t_X_train\n",
    "        [48:72]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(model, use_grid_search=True, **grid_search_params):\n",
    "    pipeline = Pipeline([\n",
    "        ('features', features_pipeline),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    if use_grid_search:\n",
    "        grid_search_params = {\n",
    "            'cv': TimeSeriesSplit(n_splits=5),\n",
    "\n",
    "            **grid_search_params\n",
    "        }\n",
    "        return GridSearchCV(pipeline, **grid_search_params)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction(model_name, y_true, y_pred):\n",
    "    rmse = math.sqrt(\n",
    "        mean_squared_error(y_true, y_pred)\n",
    "    )\n",
    "    print(f'{model_name} RMSE: ', rmse)\n",
    "    print(f'{model_name} R2 score: ', r2_score(y_true, y_pred))\n",
    "    sns.relplot(\n",
    "        x=model_name,\n",
    "        y='true values',\n",
    "        data=pd.DataFrame({\n",
    "            'true values': y_true,\n",
    "            model_name: y_pred\n",
    "        })\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, model, **grid_search_params):\n",
    "    use_grid_search = 'param_grid' in grid_search_params\n",
    "    pipeline = build_pipeline(\n",
    "        model,\n",
    "        use_grid_search=use_grid_search,\n",
    "        **grid_search_params\n",
    "    )\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print('On Train dataset:')\n",
    "    evaluate_prediction(model_name, y_train, pipeline.predict(X_train))\n",
    "    print('On Test dataset:')\n",
    "    evaluate_prediction(model_name, y_test, pipeline.predict(X_test))\n",
    "    if use_grid_search:\n",
    "        print('Best params: ', pipeline.best_params_)\n",
    "        estimator = pipeline.best_estimator_\n",
    "    estimator = pipeline\n",
    "    \n",
    "    if hasattr(estimator['model'], 'feature_importances_'):\n",
    "        feature_importance = (\n",
    "            pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': estimator['model'].feature_importances_\n",
    "            })\n",
    "            .sort_values(by='importance', ascending=False)\n",
    "            .nlargest(20, columns='importance')\n",
    "        )\n",
    "\n",
    "        g = sns.catplot(\n",
    "            x='importance',\n",
    "            y='feature',\n",
    "            kind='bar',\n",
    "            aspect=2,\n",
    "            data=feature_importance\n",
    "        )\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        g.fig.suptitle(f'Feature importance of {model_name}')\n",
    "        g.fig.savefig(\n",
    "            os.path.join(\n",
    "                FIGURES_PATH, \n",
    "                f'{model_name.replace(\" \", \"-\")}-feature-importance.png'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_forest = evaluate_model(\n",
    "    'random forest',\n",
    "    RandomForestRegressor(random_state=42, n_estimators=45, max_depth=20),\n",
    "#     param_grid={\n",
    "#         'model__n_estimators': [40, 45, 50, 55],\n",
    "#         'model__max_depth': [10, 15, 20]\n",
    "#     }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = evaluate_model(\n",
    "    'gradient boosting',\n",
    "    GradientBoostingRegressor(random_state=42, n_estimators=400),\n",
    "#     param_grid={\n",
    "#         'model__n_estimators': [280, 300, 320, 340, 360, 380, 400]\n",
    "#     }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
