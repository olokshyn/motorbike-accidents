{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
    ")\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'datasets'\n",
    "FIGURES_PATH = 'figures'\n",
    "\n",
    "season_order = ['winter', 'spring', 'summer', 'autumn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motorbike_data = (\n",
    "    pd.read_csv(\n",
    "        os.path.join(DATASET_PATH, 'cleanted_motorbike_ambulance_calls.csv'),\n",
    "        parse_dates=['date'],\n",
    "        dayfirst=False,\n",
    "    )\n",
    "    .assign(\n",
    "        yr=lambda x: np.where(\n",
    "            x['yr'] == 2011,\n",
    "            0,\n",
    "            1\n",
    "        )\n",
    "    )\n",
    "    .assign(\n",
    "        season=lambda x: (\n",
    "            pd.Categorical(\n",
    "                x['season'], \n",
    "                categories=season_order, \n",
    "                ordered=True\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    .drop(columns='was_missing')\n",
    ")\n",
    "motorbike_data.info()\n",
    "motorbike_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['date', 'hr', 'yr', 'mnth', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "categorical_features = ['season', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "target_variable = 'cnt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = motorbike_data.drop(columns=target_variable), motorbike_data[target_variable]\n",
    "\n",
    "# No time machine: use 'past' data for training, use 'future' data for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, shuffle=False\n",
    ")\n",
    "\n",
    "assert X_train.index.max() < X_test.index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMeanStdTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, feature, lags=None):\n",
    "        self.feature = feature\n",
    "        self.feature_mean_and_std = None\n",
    "        self.lags = lags\n",
    "        \n",
    "    def _get_lags(self):\n",
    "        return sorted(self.lags) if self.lags else [0]\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_mean_and_std = (\n",
    "            X[['hr', self.feature]]\n",
    "            .groupby('hr')\n",
    "            [self.feature]\n",
    "            .agg(['mean', 'std'])\n",
    "            .rename(columns={\n",
    "                'mean': f'{self.feature}_mean', \n",
    "                'std': f'{self.feature}_std'\n",
    "            })\n",
    "        )    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.feature_mean_and_std is None:\n",
    "            raise RuntimeError('Need to fit() first!')\n",
    "        \n",
    "        data_with_feature = (\n",
    "            X\n",
    "            [['date', 'hr']]\n",
    "            .merge(\n",
    "                self.feature_mean_and_std,\n",
    "                how='left',\n",
    "                left_on='hr',\n",
    "                right_index=True\n",
    "            )\n",
    "            .sort_values(['date', 'hr'])\n",
    "        )\n",
    "        \n",
    "        for lag in self._get_lags():\n",
    "            if lag == 0:\n",
    "                continue\n",
    "            data_with_feature = (\n",
    "                data_with_feature\n",
    "                .assign(**{\n",
    "                    f'{self.feature}_mean_{lag}h_lag': lambda x: (\n",
    "                        x[f'{self.feature}_mean']\n",
    "                        .shift(\n",
    "                            lag, \n",
    "                            fill_value=x.iloc[:lag][f'{self.feature}_mean'].mean()\n",
    "                        )\n",
    "                    ),\n",
    "                    f'{self.feature}_std_{lag}h_lag': lambda x: (\n",
    "                        x[f'{self.feature}_std']\n",
    "                        .shift(\n",
    "                            lag, \n",
    "                            fill_value=x.iloc[:lag][f'{self.feature}_std'].mean()\n",
    "                        )\n",
    "                    )\n",
    "                })\n",
    "            )\n",
    "            \n",
    "        if 0 not in self._get_lags():\n",
    "            data_with_feature = (\n",
    "                data_with_feature\n",
    "                .drop(columns=[f'{self.feature}_mean', f'{self.feature}_std'])\n",
    "            )\n",
    "        \n",
    "        return (\n",
    "            # We sorted, so we have to restore the original ordering\n",
    "            X\n",
    "            [['date', 'hr']]\n",
    "            .merge(\n",
    "                data_with_feature,\n",
    "                how='left',\n",
    "                on=['date', 'hr']\n",
    "            )\n",
    "            .drop(columns=['date', 'hr'])\n",
    "        )\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        names = []\n",
    "        for lag in self._get_lags():\n",
    "            if lag == 0:\n",
    "                names.extend([\n",
    "                    f'{self.feature}_mean', \n",
    "                    f'{self.feature}_std'\n",
    "                ])\n",
    "            else:\n",
    "                names.extend([\n",
    "                    f'{self.feature}_mean_{lag}h_lag', \n",
    "                    f'{self.feature}_std_{lag}h_lag'\n",
    "                ])\n",
    "        return names\n",
    "    \n",
    "(\n",
    "    FeatureMeanStdTransformer('hum', lags=[1, 2, 3, 0])\n",
    "    .fit_transform(X_train, y_train)\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CntMeanStdTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, lags=None):\n",
    "        self.feature_transformer = FeatureMeanStdTransformer('cnt', lags)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if y is None:\n",
    "            raise RuntimeError('Target variable is required for fitting!')\n",
    "        data = (\n",
    "            pd.concat(\n",
    "                [X['hr'], y],\n",
    "                axis='columns',\n",
    "                sort=False\n",
    "            )\n",
    "        )\n",
    "        self.feature_transformer.fit(data)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.feature_transformer.transform(X)\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.feature_transformer.get_feature_names()\n",
    "    \n",
    "(\n",
    "    CntMeanStdTransformer(lags=[1, 2, 3, 0])\n",
    "    .fit_transform(X_train, y_train)\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    (\n",
    "        'onehot', \n",
    "        OneHotEncoder(\n",
    "            categories='auto', \n",
    "            sparse=False, \n",
    "            handle_unknown='ignore'\n",
    "        )\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_features_pipeline = (\n",
    "    ColumnTransformer(\n",
    "        [\n",
    "            (\n",
    "                'numerical_features',\n",
    "                numerical_features_pipeline,\n",
    "                [x for x in numerical_features if x not in {'date', 'atemp'}]\n",
    "            ),\n",
    "            (\n",
    "                'categorical_features',\n",
    "                categorical_features_pipeline,\n",
    "                categorical_features\n",
    "            )\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_numerical_features_pipeline = Pipeline([\n",
    "    (\n",
    "        'custom_numerical_features',\n",
    "        FeatureUnion([\n",
    "            ('cnt_mean_std', CntMeanStdTransformer(lags=[0, 1, 2, 3])),\n",
    "            ('hum_mean_std', FeatureMeanStdTransformer('hum', lags=[0, 1, 2, 3])),\n",
    "            ('temp_mean_std', FeatureMeanStdTransformer('temp', lags=[0, 1, 2, 3]))\n",
    "        ])\n",
    "    ),\n",
    "    (\n",
    "        'numerical_features',\n",
    "        numerical_features_pipeline\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_features_pipeline = FeatureUnion([\n",
    "    ('numerical_features', custom_numerical_features_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pipeline = FeatureUnion([\n",
    "    (\n",
    "        'basic_features',\n",
    "        basic_features_pipeline\n",
    "    ),\n",
    "    (\n",
    "        'custom_features',\n",
    "        custom_features_pipeline\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(model, use_grid_search=True, **grid_search_params):\n",
    "    pipeline = Pipeline([\n",
    "        ('features', features_pipeline),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    if use_grid_search:\n",
    "        grid_search_params = {\n",
    "            'cv': TimeSeriesSplit(n_splits=5),\n",
    "\n",
    "            **grid_search_params\n",
    "        }\n",
    "        return GridSearchCV(pipeline, **grid_search_params)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction(model_name, y_true, y_pred):\n",
    "    rmse = math.sqrt(\n",
    "        mean_squared_error(y_true, y_pred)\n",
    "    )\n",
    "    print(f'{model_name} RMSE: ', rmse)\n",
    "    print(f'{model_name} R2 score: ', r2_score(y_true, y_pred))\n",
    "    sns.relplot(\n",
    "        x=model_name,\n",
    "        y='true values',\n",
    "        data=pd.DataFrame({\n",
    "            'true values': y_true,\n",
    "            model_name: y_pred\n",
    "        })\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, model, **grid_search_params):\n",
    "    pipeline = build_pipeline(\n",
    "        model,\n",
    "        use_grid_search='param_grid' in grid_search_params,\n",
    "        **grid_search_params\n",
    "    )\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    evaluate_prediction(model_name, y_test, pipeline.predict(X_test))\n",
    "    if hasattr(pipeline, 'best_params_'):\n",
    "        print('Best params: ', pipeline.best_params_)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_forest = evaluate_model(\n",
    "    'random forest',\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid={\n",
    "        # Already found the best params\n",
    "        'model__n_estimators': [45, 50],\n",
    "        'model__max_depth': [15]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
